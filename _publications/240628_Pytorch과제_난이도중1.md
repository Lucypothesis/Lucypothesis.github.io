# Pytorch과제-난이도중1

### **~ 미션 ~**

1. Pytorch의 Dataset & Dataloader에 대한 이해
2. Dataloader의 Sampler, Collate Function에 대한 이해

### **~ 세부 TODO 항목들 ~**

1. [Dataset & Dataloader 개요](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) 읽고 정리하기 (난이도 하)
2. [Dataset & Dataloader 내부](https://pytorch.org/docs/stable/data.html) 읽고 정리하기 (난이도 중)
3. Fashion MNSIT를 적당한 CNN 모형으로 훈련
4. Fashion MNIST 데이터셋을 Sampler를 통해 일부의 데이터만 레이블을 활용하도록 변경
4-1. 훈련 데이터가 60,000개라면, 6,000개의 레이블 데이터, 54,000개의 레이블이 없는 데이터를 활용
4-2. 하나의 배치는 모두 레이블이 없거나, 모두 레이블이 있어야 함
4-3. 레이블이 있는 배치라면 -> 교차 엔트로피로 훈련 / 레이블이 없는 배치라면 -> pass
5. 3, 4의 훈련/검증 세트의 손실값 및 정확도 비교

##1. Dataset & Dataloader 개요 읽고 정리하기 (난이도 하)

https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files

- PyTorch는 `torch.utils.data.DataLoader`,`torch.utils.data.Dataset`과 같은 데이터셋을 로드할 수 있는 두 개의 모델을 제공함
- Dataset에는 다양한 데이터 샘플과 라벨이 들어있는데, 이번에는 TorchVision에서 나온 Fashion-MNIST 데이터셋을 사용해볼거임. 이 데이터셋은 Zalando라는 패션회사에서 쓰는 60,000개의 훈련 이미지데이터와 10,000개의 테스트 이미지데이터로 구성되어 있음
- 파라미터 설명:
  - `root`: 데이터가 있는 곳
  - `train`: train이냐 test냐의 boolean값
  - `download=True`: 데이터가 root에 없으면 인터넷에서 데이터를 다운로드함
  - `transform`, `target_transform`: feature와 레이블 변환을 지정함

### 1.0 데이터 가져오기


```python
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

training_data = datasets.FashionMNIST(
    root = 'data',
    train = True,
    download = True,

    # ToTensor(): 이미지를 텐서로 변환
    transform = ToTensor()
)

test_data = datasets.FashionMNIST(
    root = 'data',
    train = False,
    download = True,
    transform = ToTensor()
)
```

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz
    

    100%|██████████| 26421880/26421880 [00:00<00:00, 117189349.01it/s]
    

    Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz
    

    100%|██████████| 29515/29515 [00:00<00:00, 10254711.94it/s]

    Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
    

    
    100%|██████████| 4422102/4422102 [00:00<00:00, 62915157.55it/s]
    

    Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
    

    100%|██████████| 5148/5148 [00:00<00:00, 3938040.67it/s]
    

    Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw
    
    

###1.1 데이터 반복 및 시각화하기


```python
labels_map = {
    0: 'T-Shirt',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle Boot'
}

figure = plt.figure(figsize=(8,8))
cols, rows = 3, 3
for i in range(1, cols*rows+1):
  sample_idx = torch.randint(len(training_data), size=(1,)).item()
  img, label = training_data[sample_idx]
  figure.add_subplot(rows, cols, i)
  plt.title(labels_map[label])
  plt.axis('off')
  plt.imshow(img.squeeze(), cmap='gray')
plt.show()
```


    
![png](240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_files/240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_11_0.png)
    


###1.2 사용자 정의 데이터셋 만들기

- `__init__`,`__len__`,`__getitem__`이 필수로 들어가야 함
- FashionMNIST 이미지는 `img_dir`라는 디렉토리에 있고, 레이블은 `annotations_file`라는 csv파일에 별도로 저장되어 있음

- `__getitem__`: 데이터셋에서 인덱스(idx)에 해당하는 데이터샘플을 로드하고 가져옴
  - idx를 바탕으로 이미지의 위치를 확인하고, `read_image`를 통해 이를 텐서로 반환한 다음, `self.img_labels`의 csv 데이터에서 해당 레이블을 검색하고, 적용 가능하다면 transform 함수를 적용해서 텐서 이미지와 해당 레이블을 튜플로 반환함


```python
import os
import pandas as pd
from torchvision.io import read_image

class CustomImageDataset(Dataset):
  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
    self.img_labels = pd.read_csv(annotations_file)
    self.img_dir = img_dir
    self.transform = transform
    self.target_transform = target_transform

  def __len__(self):
    return len(self.img_labels)

  def __getitems(self, idx):
    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])
    image = read_image(img_path)
    label = self.img_labels.iloc[idx,1]
    if self.transform:
      image = self.transform(image)
    if self.target_transform:
      label = self.target_transform(label)
    return image, label
```

### 1.3 DataLoaders로 데이터 준비하기

- `Dataset`는 데이터셋의 피쳐와 레이블을 한번에 하나씩만 검색함
- 모델을 학습시킬 때
  - 샘플을 minibatches 형태로 넣고
  - 오버피팅을 방지하기 위해서 1에폭마다 데이터를 셔플하며
  - 데이터 검색속도를 높이기 위해 파이썬의 `multiprocessing`을 사용하고자 함


```python
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)
```

- 이제 DataLoader 안에 데이터셋을 넣었으니 돌려줄거임

### 1.4 DataLoader로 반복하기

- 매 iteration마다 train_feature와 train_label의 배치를 반환함
- `shuffle=True`이므로 모든 배치를 반복한 후에는 데이터가 셔플됨

##2. Dataset & Dataloader 내부 읽고 정리하기 (난이도 중)

###2.1 Dataset Types

- `DataLoader`의 가장 중요한 인수는 `dataset`임. PyTorch는 두 가지 타입의 `dataset`을 지원함

2.1.1 Map-style datasets
- `__getitem()__`과 `__len__`을 구현
- 인덱스/키와 데이터샘플을 매핑함
  - e.g. `dataset[idx]`에 접근하면, `idx`번째 이미지와 레이블을 읽을 수 있음

2.1.2 Iterable-style datasets
- `__iter__()`을 구현
- 무작위 읽기가 어렵거나 불가능할 때, 또는 가져온 데이터에 따라 batch size가 달라지는 경우에 적합
  - e.g. 데이터 집합을 `iter(dataset)`로 호출하면 데이터베이스, 원격 서버 또는 실시간으로 생성된 로그에서 읽은 데이터를 반환할 수 있음

### 2.2 Data Loading Order와 `Sampler`

##3. Fashion MNSIT를 적당한 CNN 모형으로 훈련

### 3.0 라이브러리 임포트 & 데이터 준비


```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import FashionMNIST
from torchvision.transforms import ToTensor
from tqdm import tqdm
```


```python
training_data = FashionMNIST(
    root = 'data',
    train = True,
    download = True,
    transform = ToTensor()
)

test_data = FashionMNIST(
    root = 'data',
    train = False,
    download = True,
    transform = ToTensor()
)
```


```python
train_loader = DataLoader(training_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
```

### 3.3 Training, evaluation, training_loop 함수 정의


```python
def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):
    model.train()
    train_loss = 0.0
    train_accuracy = 0

    tbar = tqdm(dataloader)
    for images, labels in tbar:
        images = images.to(device)
        labels = labels.to(device)

        # 순전파
        outputs = model(images)
        loss = criterion(outputs, labels)

        # 역전파와 최적화
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(outputs, dim=1)
        train_accuracy += (predicted == labels).sum().item()

        tbar.set_description(f'Epoch[{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}')

    train_loss = train_loss / len(dataloader)
    train_accuracy = train_accuracy / len(train_dataset)

    return model, train_loss, train_accuracy
```


```python
def evaluation(model, dataloader, val_dataset, criterion, device, epoch, num_epochs):
    model.eval()
    valid_loss = 0.0
    valid_accuracy = 0

    with torch.no_grad():
        tbar = tqdm(dataloader)
        for images, labels in tbar:
            images = images.to(device)
            labels = labels.to(device)

            # 순전파
            outputs = model(images)
            loss = criterion(outputs, labels)

            valid_loss += loss.item()
            _, predicted = torch.max(outputs, dim=1)
            valid_accuracy += (predicted == labels).sum().item()

            tbar.set_description(f'Epoch[{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}')

        valid_loss = valid_loss / len(dataloader)
        valid_accuracy = valid_accuracy / len(val_dataset)

    return model, valid_loss, valid_accuracy
```


```python
def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):
    best_valid_loss = float('inf')
    early_stop_counter = 0
    valid_max_accuracy = -1

    train_losses = []
    valid_losses = []
    train_accuracies = []
    valid_accuracies = []

    for epoch in range(num_epochs):
        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)
        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)

        train_losses.append(train_loss)
        valid_losses.append(valid_loss)
        train_accuracies.append(train_accuracy)
        valid_accuracies.append(valid_accuracy)

        if valid_accuracy > valid_max_accuracy:
            valid_max_accuracy = valid_accuracy

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            torch.save(model.state_dict(), f'./model_{model_name}.pt')
            early_stop_counter = 0
        else:
            early_stop_counter += 1

        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')

        if early_stop_counter >= patience:
            print('Early stopping')
            break

    return model, valid_max_accuracy
```

### 3.4 파라미터 정의


```python
num_epochs = 10
patience = 3
model_name = "FashionMNIST_CNN"
```

### 3.1 CNN모델 정의


```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = x.view(-1, 64 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

### 3.2 모델 초기화, 손실함수 정의, 최적화 알고리즘 설정, 디바이스 설정, 모델을 디바이스로 이동


```python
model1 = CNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model1.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model1.to(device)
```




    CNN(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (fc1): Linear(in_features=3136, out_features=128, bias=True)
      (fc2): Linear(in_features=128, out_features=10, bias=True)
      (dropout): Dropout(p=0.25, inplace=False)
    )



### 3.5 학습과 평가 진행


```python
model1, valid_max_accuracy = training_loop(model1, train_loader, test_loader, training_data, test_data, criterion, optimizer, device, num_epochs, patience, model_name)
print('\n')
print(f'Best Validation Accuracy: {valid_max_accuracy:.4f}')
```

      0%|          | 0/938 [00:00<?, ?it/s]
    


    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-41-cc58978e0aa7> in <cell line: 1>()
    ----> 1 model1, valid_max_accuracy = training_loop(model1, train_loader, test_loader, training_data, test_data, criterion, optimizer, device, num_epochs, patience, model_name)
          2 print('\n')
          3 print(f'Best Validation Accuracy: {valid_max_accuracy:.4f}')
    

    <ipython-input-37-36fc75df2854> in training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)
         10 
         11     for epoch in range(num_epochs):
    ---> 12         model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)
         13         model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)
         14 
    

    <ipython-input-35-a4873ab960c8> in training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)
         11         # 순전파
         12         outputs = model(images)
    ---> 13         loss = criterion(outputs, labels)
         14 
         15         # 역전파와 최적화
    

    /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _wrapped_call_impl(self, *args, **kwargs)
       1530             return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
       1531         else:
    -> 1532             return self._call_impl(*args, **kwargs)
       1533 
       1534     def _call_impl(self, *args, **kwargs):
    

    /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
       1539                 or _global_backward_pre_hooks or _global_backward_hooks
       1540                 or _global_forward_hooks or _global_forward_pre_hooks):
    -> 1541             return forward_call(*args, **kwargs)
       1542 
       1543         try:
    

    /usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py in forward(self, input, target)
       1183 
       1184     def forward(self, input: Tensor, target: Tensor) -> Tensor:
    -> 1185         return F.cross_entropy(input, target, weight=self.weight,
       1186                                ignore_index=self.ignore_index, reduction=self.reduction,
       1187                                label_smoothing=self.label_smoothing)
    

    /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)
       3084     if size_average is not None or reduce is not None:
       3085         reduction = _Reduction.legacy_get_string(size_average, reduce)
    -> 3086     return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
       3087 
       3088 
    

    ValueError: Expected input batch_size (1024) to match target batch_size (64).


- Train Loss는 계속해서 감소하고 있고 Train Accuracy는 계속해서 증가하고 있음
- Valid Loss는 초기에 감소하다가 후반부에는 큰 변화없이 유지되고 있음. Valid Accuracy는 초기에 증가하다가 후반부에는 큰 변화없이 일정 수준에서 안정화되고 있음   
=> 오버피팅 없이 학습이 잘 되었다고 판단됨



```python
from sklearn.metrics import accuracy_score
import numpy as np

def evaluate(model, dataloader, device):
    model.load_state_dict(torch.load(f'./model_{model_name}.pt'))
    model = model.to(device)
    model.eval()
    total_labels = []
    total_preds = []
    total_loss = 0.0

    criterion = nn.CrossEntropyLoss()

    with torch.no_grad():
        tbar = tqdm(dataloader)
        for images, labels in tbar:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            _, predicted = torch.max(outputs, dim=1)

            total_preds.extend(predicted.detach().cpu().tolist())
            total_labels.extend(labels.detach().cpu().tolist())

            tbar.set_description(f'Test Loss: {loss.item():.4f}')

    total_loss = total_loss / len(dataloader)
    total_preds = np.array(total_preds)
    total_labels = np.array(total_labels)
    accuracy = accuracy_score(total_labels, total_preds)
    print(f'Model accuracy on test data: {accuracy}')
    return total_loss, accuracy

# Evaluate the model on the test set
test_loss, test_accuracy = evaluate(model, test_loader, device)
print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}')
```

- Test Accuracy가 0.9205로 조금 아쉽게 나왔음
- 개선방법
  - Adaptive pooling을 두 개 추가

### 과연 정확도가 얼마나 오를 것인가


```python
class newCNN(nn.Module):
    def __init__(self):
        super(newCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.adaptive_pool1 = nn.AdaptiveAvgPool2d((14, 14))
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.adaptive_pool2 = nn.AdaptiveAvgPool2d((7, 7))
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.adaptive_pool1(x)
        x = torch.relu(self.conv2(x))
        x = self.adaptive_pool2(x)
        x = x.view(-1, 64 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```


```python
model2 = newCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model2.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model2.to(device)
```


```python
model2, valid_max_accuracy = training_loop(model2, train_loader, test_loader, training_data, test_data, criterion, optimizer, device, num_epochs, patience, model_name)
print('\n')
print(f'Best Validation Accuracy: {valid_max_accuracy:.4f}')
```

- 시간이 비교적 많이 걸렸다.
-


```python
test_loss, test_accuracy = evaluate(model2, test_loader, device)
print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}')
```

- 어라? 정확도가 0.9205에서 0.9230으로 정말 미세하게밖에 오르지 않았다. 헐 adaptive pooling을 두 개 추가하고 dropout 비율까지 조정해줬는데 뭐가 문제인걸까

##4. Fashion MNIST 데이터셋을 Sampler를 통해 일부의 데이터만 레이블을 활용하도록 변경

###4.1 훈련 데이터가 60,000개라면, 6,000개의 레이블 데이터, 54,000개의 레이블이 없는 데이터를 활용

###4.2 하나의 배치는 모두 레이블이 없거나, 모두 레이블이 있어야 함

###4.3 레이블이 있는 배치라면 -> 교차 엔트로피로 훈련 / 레이블이 없는 배치라면 -> pass

##5. 3, 4의 훈련/검증 세트의 손실값 및 정확도 비교
