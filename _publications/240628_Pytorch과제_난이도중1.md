# Pytorch과제-난이도중1

### **~ 미션 ~**

1. Pytorch의 Dataset & Dataloader에 대한 이해
2. Dataloader의 Sampler, Collate Function에 대한 이해

### **~ 세부 TODO 항목들 ~**

1. [Dataset & Dataloader 개요](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) 읽고 정리하기 (난이도 하)
2. [Dataset & Dataloader 내부](https://pytorch.org/docs/stable/data.html) 읽고 정리하기 (난이도 중)
3. Fashion MNSIT를 적당한 CNN 모형으로 훈련
4. Fashion MNIST 데이터셋을 Sampler를 통해 일부의 데이터만 레이블을 활용하도록 변경
4-1. 훈련 데이터가 60,000개라면, 6,000개의 레이블 데이터, 54,000개의 레이블이 없는 데이터를 활용
4-2. 하나의 배치는 모두 레이블이 없거나, 모두 레이블이 있어야 함
4-3. 레이블이 있는 배치라면 -> 교차 엔트로피로 훈련 / 레이블이 없는 배치라면 -> pass
5. 3, 4의 훈련/검증 세트의 손실값 및 정확도 비교

##1. Dataset & Dataloader 개요 읽고 정리하기 (난이도 하)

https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files

- PyTorch는 `torch.utils.data.DataLoader`,`torch.utils.data.Dataset`과 같은 데이터셋을 로드할 수 있는 두 개의 모델을 제공함
- Dataset에는 다양한 데이터 샘플과 라벨이 들어있는데, 이번에는 TorchVision에서 나온 Fashion-MNIST 데이터셋을 사용해볼거임. 이 데이터셋은 Zalando라는 패션회사에서 쓰는 60,000개의 훈련 이미지데이터와 10,000개의 테스트 이미지데이터로 구성되어 있음
- 파라미터 설명:
  - `root`: 데이터가 있는 곳
  - `train`: train이냐 test냐의 boolean값
  - `download=True`: 데이터가 root에 없으면 인터넷에서 데이터를 다운로드함
  - `transform`, `target_transform`: feature와 레이블 변환을 지정함

### 1.0 데이터 가져오기


```python
import torch
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

training_data = datasets.FashionMNIST(
    root = 'data',
    train = True,
    download = True,

    # ToTensor(): 이미지를 텐서로 변환
    transform = ToTensor()
)

test_data = datasets.FashionMNIST(
    root = 'data',
    train = False,
    download = True,
    transform = ToTensor()
)
```

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz
    

    100%|██████████| 26421880/26421880 [00:00<00:00, 117189349.01it/s]
    

    Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz
    

    100%|██████████| 29515/29515 [00:00<00:00, 10254711.94it/s]

    Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
    

    
    100%|██████████| 4422102/4422102 [00:00<00:00, 62915157.55it/s]
    

    Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
    

    100%|██████████| 5148/5148 [00:00<00:00, 3938040.67it/s]
    

    Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw
    
    

###1.1 데이터 반복 및 시각화하기


```python
labels_map = {
    0: 'T-Shirt',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle Boot'
}

figure = plt.figure(figsize=(8,8))
cols, rows = 3, 3
for i in range(1, cols*rows+1):
  sample_idx = torch.randint(len(training_data), size=(1,)).item()
  img, label = training_data[sample_idx]
  figure.add_subplot(rows, cols, i)
  plt.title(labels_map[label])
  plt.axis('off')
  plt.imshow(img.squeeze(), cmap='gray')
plt.show()
```


    
![png](240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_files/240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_11_0.png)
    


###1.2 사용자 정의 데이터셋 만들기

- `__init__`,`__len__`,`__getitem__`이 필수로 들어가야 함
- FashionMNIST 이미지는 `img_dir`라는 디렉토리에 있고, 레이블은 `annotations_file`라는 csv파일에 별도로 저장되어 있음

- `__getitem__`: 데이터셋에서 인덱스(idx)에 해당하는 데이터샘플을 로드하고 가져옴
  - idx를 바탕으로 이미지의 위치를 확인하고, `read_image`를 통해 이를 텐서로 반환한 다음, `self.img_labels`의 csv 데이터에서 해당 레이블을 검색하고, 적용 가능하다면 transform 함수를 적용해서 텐서 이미지와 해당 레이블을 튜플로 반환함


```python
import os
import pandas as pd
from torchvision.io import read_image

class CustomImageDataset(Dataset):
  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
    self.img_labels = pd.read_csv(annotations_file)
    self.img_dir = img_dir
    self.transform = transform
    self.target_transform = target_transform

  def __len__(self):
    return len(self.img_labels)

  def __getitems(self, idx):
    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])
    image = read_image(img_path)
    label = self.img_labels.iloc[idx,1]
    if self.transform:
      image = self.transform(image)
    if self.target_transform:
      label = self.target_transform(label)
    return image, label
```

### 1.3 DataLoaders로 데이터 준비하기

- `Dataset`는 데이터셋의 피쳐와 레이블을 한번에 하나씩만 검색함
- 모델을 학습시킬 때
  - 샘플을 minibatches 형태로 넣고
  - 오버피팅을 방지하기 위해서 1에폭마다 데이터를 셔플하며
  - 데이터 검색속도를 높이기 위해 파이썬의 `multiprocessing`을 사용하고자 함


```python
from torch.utils.data import DataLoader

train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)
```

- 이제 DataLoader 안에 데이터셋을 넣었으니 돌려줄거임

### 1.4 DataLoader로 반복하기

- 매 iteration마다 train_feature와 train_label의 배치를 반환함
- `shuffle=True`이므로 모든 배치를 반복한 후에는 데이터가 셔플됨

---

##2. Dataset & Dataloader 내부 읽고 정리하기 (난이도 중)

###2.1 Dataset Types

- `DataLoader`의 가장 중요한 인수는 `dataset`임. PyTorch는 두 가지 타입의 `dataset`을 지원함

2.1.1 Map-style datasets
- `__getitem()__`과 `__len__`을 구현
- 인덱스/키와 데이터샘플을 매핑함
  - e.g. `dataset[idx]`에 접근하면 `idx`번째 이미지와 레이블을 읽을 수 있음

2.1.2 Iterable-style datasets
- `__iter__()`을 구현
- 무작위 읽기가 어렵거나 불가능할 때, 또는 가져온 데이터에 따라 batch size가 달라지는 경우에 적합
  - e.g. 데이터 집합을 `iter(dataset)`로 호출하면 데이터베이스, 원격 서버 또는 실시간으로 생성된 로그에서 읽은 데이터를 반환할 수 있음

### 2.2 Data Loading Order와 `Sampler`

- Iterable-style datasets는 사용자가 정의한 iterable에 의해 완전히 제어됨. 이것은 chunk-reading과 dynamic batch size를 더 쉽게 구현할 수 있음
- 나머지는 map-style datasets과 관련이 있음. 이때 `torch.utils.data.Sampler` 클래스가 사용됨. e.g. SGD에서, `Sampler`는 indices를 랜덤하게 나열해서(SGD에서는 한 번에 하나, mini-batch SGD에서는 한 번에 적은 수) 산출함
- 이렇게 구성된 sampler는 `shuffler`를 통해 자동으로 `DataLoader`에 구성되지만, 사용자가 custom `Sampler`를 구성해서 다음에 가져올 인덱스/키를 설정할 수 있음
- 이러한 custom `Sampler`는 `batch_sampler`의 인수로 전달될 수 있음. Automatic batching은 `batch_size`와 `drop_last`를 통해서도 실행될 수 있음   

+ 주의할 점: `sampler`와 `batch_sampler`는 모두 iterable-style datasets와는 호환되지 않음. iterable-style datasets는 키/인덱스 개념이 없기 때문

### 2.3 Batched data와 Non-Batched data의 로딩

- `DataLoader`는 `batch_size`, `drop_last`, `batch_sampler`, `collate_fm`을 통해 가져온 샘플들을 배치로 자동으로 조정할 수 있도록 함
- `batch_size`가 `None`이 아닐 때, data loader는 개별 샘플이 아니라 batched된 샘플들을 만듦. `batch_size`와 `drop_last`는 data loader가 어떻게 dataset key의 batch들을 갖고 있는지 설명해줌. Map-style datasets에서는 이 두 개 대신 `batch_sampler`를 사용할 수도 있음

2.3.1 (기본) Automatic batching

- 가장 일반적인 경우임

2.3.2 Automatic batching 비활성화

2.3.3 `collate_fn` 사용하기

---

##3. Fashion MNSIT를 적당한 CNN 모형으로 훈련

### 3.0 라이브러리 임포트 & 데이터 준비


```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import FashionMNIST
from torchvision.transforms import ToTensor
from tqdm import tqdm
```


```python
training_data = FashionMNIST(
    root = 'data',
    train = True,
    download = True,
    transform = ToTensor()
)

test_data = FashionMNIST(
    root = 'data',
    train = False,
    download = True,
    transform = ToTensor()
)
```


```python
train_loader = DataLoader(training_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
```

### 3.1 Training, evaluation, training_loop 함수 정의


```python
def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):
    model.train()
    train_loss = 0.0
    train_accuracy = 0

    tbar = tqdm(dataloader)
    for images, labels in tbar:
        images = images.to(device)
        labels = labels.to(device)

        # 순전파
        outputs = model(images)
        loss = criterion(outputs, labels)

        # 역전파와 최적화
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(outputs, dim=1)
        train_accuracy += (predicted == labels).sum().item()

        tbar.set_description(f'Epoch[{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}')

    train_loss = train_loss / len(dataloader)
    train_accuracy = train_accuracy / len(train_dataset)

    return model, train_loss, train_accuracy
```


```python
def evaluation(model, dataloader, val_dataset, criterion, device, epoch, num_epochs):
    model.eval()
    valid_loss = 0.0
    valid_accuracy = 0

    with torch.no_grad():
        tbar = tqdm(dataloader)
        for images, labels in tbar:
            images = images.to(device)
            labels = labels.to(device)

            # 순전파
            outputs = model(images)
            loss = criterion(outputs, labels)

            valid_loss += loss.item()
            _, predicted = torch.max(outputs, dim=1)
            valid_accuracy += (predicted == labels).sum().item()

            tbar.set_description(f'Epoch[{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}')

        valid_loss = valid_loss / len(dataloader)
        valid_accuracy = valid_accuracy / len(val_dataset)

    return model, valid_loss, valid_accuracy
```


```python
def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):
    best_valid_loss = float('inf')
    early_stop_counter = 0
    valid_max_accuracy = -1

    for epoch in range(num_epochs):
        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)
        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)

        if valid_accuracy > valid_max_accuracy:
            valid_max_accuracy = valid_accuracy

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            torch.save(model.state_dict(), f'./model_{model_name}.pt')
            early_stop_counter = 0
        else:
            early_stop_counter += 1

        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')

        if early_stop_counter >= patience:
            print('Early stopping')
            break

    return model, valid_max_accuracy
```

### 3.2 기본 CNN모델

3.2.1 CNN 모델 정의


```python
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

3.2.2 모델, 손실함수, 옵티마이저 정의


```python
model1 = CNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model1.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model1.to(device)
```




    CNN(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (fc1): Linear(in_features=3136, out_features=128, bias=True)
      (fc2): Linear(in_features=128, out_features=10, bias=True)
      (dropout): Dropout(p=0.25, inplace=False)
    )



3.2.3. 학습과 평가 진행


```python
num_epochs = 10
patience = 3
model_name = "FashionMNIST_CNN"

model1, valid_max_accuracy = training_loop(model1, train_loader, test_loader, training_data, test_data, criterion, optimizer, device, num_epochs, patience, model_name)
print('\n')
print(f'Best Validation Accuracy: {valid_max_accuracy:.4f}')
```

    Epoch[1/10], Train Loss: 0.3929: 100%|██████████| 938/938 [00:10<00:00, 88.39it/s]
    Epoch[1/10], Valid Loss: 0.2038: 100%|██████████| 157/157 [00:01<00:00, 108.26it/s]
    

    Epoch [1/10], Train Loss: 0.5322, Train Accuracy: 0.8038, Valid Loss: 0.3614, Valid Accuracy: 0.8676
    

    Epoch[2/10], Train Loss: 0.3492: 100%|██████████| 938/938 [00:10<00:00, 89.25it/s]
    Epoch[2/10], Valid Loss: 0.2887: 100%|██████████| 157/157 [00:01<00:00, 107.17it/s]
    

    Epoch [2/10], Train Loss: 0.3372, Train Accuracy: 0.8784, Valid Loss: 0.3086, Valid Accuracy: 0.8869
    

    Epoch[3/10], Train Loss: 0.2200: 100%|██████████| 938/938 [00:10<00:00, 89.35it/s]
    Epoch[3/10], Valid Loss: 0.2151: 100%|██████████| 157/157 [00:01<00:00, 96.19it/s]
    

    Epoch [3/10], Train Loss: 0.2922, Train Accuracy: 0.8929, Valid Loss: 0.2758, Valid Accuracy: 0.8985
    

    Epoch[4/10], Train Loss: 0.1813: 100%|██████████| 938/938 [00:10<00:00, 87.82it/s]
    Epoch[4/10], Valid Loss: 0.1732: 100%|██████████| 157/157 [00:01<00:00, 104.36it/s]
    

    Epoch [4/10], Train Loss: 0.2627, Train Accuracy: 0.9045, Valid Loss: 0.2617, Valid Accuracy: 0.9037
    

    Epoch[5/10], Train Loss: 0.2334: 100%|██████████| 938/938 [00:10<00:00, 88.11it/s]
    Epoch[5/10], Valid Loss: 0.2463: 100%|██████████| 157/157 [00:01<00:00, 106.53it/s]
    

    Epoch [5/10], Train Loss: 0.2402, Train Accuracy: 0.9110, Valid Loss: 0.2554, Valid Accuracy: 0.9052
    

    Epoch[6/10], Train Loss: 0.0825: 100%|██████████| 938/938 [00:10<00:00, 89.58it/s]
    Epoch[6/10], Valid Loss: 0.1645: 100%|██████████| 157/157 [00:01<00:00, 103.29it/s]
    

    Epoch [6/10], Train Loss: 0.2221, Train Accuracy: 0.9177, Valid Loss: 0.2450, Valid Accuracy: 0.9126
    

    Epoch[7/10], Train Loss: 0.2341: 100%|██████████| 938/938 [00:10<00:00, 88.75it/s]
    Epoch[7/10], Valid Loss: 0.1777: 100%|██████████| 157/157 [00:01<00:00, 105.64it/s]
    

    Epoch [7/10], Train Loss: 0.2022, Train Accuracy: 0.9253, Valid Loss: 0.2371, Valid Accuracy: 0.9148
    

    Epoch[8/10], Train Loss: 0.1003: 100%|██████████| 938/938 [00:10<00:00, 89.48it/s]
    Epoch[8/10], Valid Loss: 0.1881: 100%|██████████| 157/157 [00:01<00:00, 104.29it/s]
    

    Epoch [8/10], Train Loss: 0.1880, Train Accuracy: 0.9301, Valid Loss: 0.2371, Valid Accuracy: 0.9167
    

    Epoch[9/10], Train Loss: 0.0909: 100%|██████████| 938/938 [00:10<00:00, 88.70it/s]
    Epoch[9/10], Valid Loss: 0.2197: 100%|██████████| 157/157 [00:01<00:00, 107.99it/s]
    

    Epoch [9/10], Train Loss: 0.1750, Train Accuracy: 0.9348, Valid Loss: 0.2547, Valid Accuracy: 0.9153
    

    Epoch[10/10], Train Loss: 0.0652: 100%|██████████| 938/938 [00:10<00:00, 89.22it/s]
    Epoch[10/10], Valid Loss: 0.1381: 100%|██████████| 157/157 [00:01<00:00, 107.77it/s]
    

    Epoch [10/10], Train Loss: 0.1613, Train Accuracy: 0.9394, Valid Loss: 0.2306, Valid Accuracy: 0.9189
    
    
    Best Validation Accuracy: 0.9189
    

- Train Loss는 계속해서 감소하고 있고 Train Accuracy는 계속해서 증가하고 있음
- Valid Loss는 초기에 감소하다가 후반부에는 큰 변화없이 유지되고 있음. Valid Accuracy는 초기에 증가하다가 후반부에는 큰 변화없이 일정 수준에서 안정화되고 있음   
=> 오버피팅 없이 학습이 잘 되었다고 판단됨


- but! Test Accuracy가 0.9189로 조금 아쉽게 나왔음
  => CNN 모델을 새로 만들어서 학습시켜볼거임


### 3.3 new CNN모델

- 개선방법
  - Adaptive pooling을 두 개 추가

3.3.1 new CNN 모델 정의


```python
class newCNN(nn.Module):
    def __init__(self):
        super(newCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.adaptive_pool1 = nn.AdaptiveAvgPool2d((14, 14))
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.adaptive_pool2 = nn.AdaptiveAvgPool2d((7, 7))
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.adaptive_pool1(x)
        x = torch.relu(self.conv2(x))
        x = self.adaptive_pool2(x)
        x = x.view(-1, 64 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

3.3.2 모델, 손실함수, 옵티마이저 정의


```python
model2 = newCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model2.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model2.to(device)
```




    newCNN(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (adaptive_pool1): AdaptiveAvgPool2d(output_size=(14, 14))
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (adaptive_pool2): AdaptiveAvgPool2d(output_size=(7, 7))
      (fc1): Linear(in_features=3136, out_features=128, bias=True)
      (fc2): Linear(in_features=128, out_features=10, bias=True)
      (dropout): Dropout(p=0.25, inplace=False)
    )



3.3.3. 학습과 평가 진행


```python
num_epochs = 10
patience = 3
model_name = "FashionMNIST_CNN"

model2, valid_max_accuracy = training_loop(model2, train_loader, test_loader, training_data, test_data, criterion, optimizer, device, num_epochs, patience, model_name)
print('\n')
print(f'Best Validation Accuracy: {valid_max_accuracy:.4f}')
```

    Epoch[1/10], Train Loss: 0.3372: 100%|██████████| 938/938 [00:10<00:00, 89.70it/s]
    Epoch[1/10], Valid Loss: 0.2150: 100%|██████████| 157/157 [00:01<00:00, 105.29it/s]
    

    Epoch [1/10], Train Loss: 0.5757, Train Accuracy: 0.7881, Valid Loss: 0.3969, Valid Accuracy: 0.8530
    

    Epoch[2/10], Train Loss: 0.4710: 100%|██████████| 938/938 [00:10<00:00, 89.58it/s]
    Epoch[2/10], Valid Loss: 0.2247: 100%|██████████| 157/157 [00:01<00:00, 110.68it/s]
    

    Epoch [2/10], Train Loss: 0.3734, Train Accuracy: 0.8645, Valid Loss: 0.3346, Valid Accuracy: 0.8790
    

    Epoch[3/10], Train Loss: 0.1825: 100%|██████████| 938/938 [00:10<00:00, 89.92it/s]
    Epoch[3/10], Valid Loss: 0.1195: 100%|██████████| 157/157 [00:01<00:00, 105.64it/s]
    

    Epoch [3/10], Train Loss: 0.3254, Train Accuracy: 0.8822, Valid Loss: 0.3114, Valid Accuracy: 0.8833
    

    Epoch[4/10], Train Loss: 0.2321: 100%|██████████| 938/938 [00:10<00:00, 90.67it/s]
    Epoch[4/10], Valid Loss: 0.1156: 100%|██████████| 157/157 [00:01<00:00, 106.53it/s]
    

    Epoch [4/10], Train Loss: 0.2940, Train Accuracy: 0.8940, Valid Loss: 0.2928, Valid Accuracy: 0.8916
    

    Epoch[5/10], Train Loss: 0.2793: 100%|██████████| 938/938 [00:10<00:00, 88.52it/s]
    Epoch[5/10], Valid Loss: 0.0948: 100%|██████████| 157/157 [00:01<00:00, 102.66it/s]
    

    Epoch [5/10], Train Loss: 0.2747, Train Accuracy: 0.8995, Valid Loss: 0.2835, Valid Accuracy: 0.8982
    

    Epoch[6/10], Train Loss: 0.1934: 100%|██████████| 938/938 [00:10<00:00, 89.59it/s]
    Epoch[6/10], Valid Loss: 0.0562: 100%|██████████| 157/157 [00:01<00:00, 108.11it/s]
    

    Epoch [6/10], Train Loss: 0.2579, Train Accuracy: 0.9045, Valid Loss: 0.2773, Valid Accuracy: 0.8983
    

    Epoch[7/10], Train Loss: 0.2608: 100%|██████████| 938/938 [00:10<00:00, 87.28it/s]
    Epoch[7/10], Valid Loss: 0.1053: 100%|██████████| 157/157 [00:01<00:00, 106.69it/s]
    

    Epoch [7/10], Train Loss: 0.2454, Train Accuracy: 0.9113, Valid Loss: 0.2690, Valid Accuracy: 0.9019
    

    Epoch[8/10], Train Loss: 0.1622: 100%|██████████| 938/938 [00:10<00:00, 88.49it/s]
    Epoch[8/10], Valid Loss: 0.0587: 100%|██████████| 157/157 [00:01<00:00, 107.56it/s]
    

    Epoch [8/10], Train Loss: 0.2302, Train Accuracy: 0.9152, Valid Loss: 0.2529, Valid Accuracy: 0.9077
    

    Epoch[9/10], Train Loss: 0.4732: 100%|██████████| 938/938 [00:10<00:00, 89.70it/s]
    Epoch[9/10], Valid Loss: 0.0636: 100%|██████████| 157/157 [00:01<00:00, 106.28it/s]
    

    Epoch [9/10], Train Loss: 0.2186, Train Accuracy: 0.9204, Valid Loss: 0.2515, Valid Accuracy: 0.9092
    

    Epoch[10/10], Train Loss: 0.3106: 100%|██████████| 938/938 [00:10<00:00, 89.35it/s]
    Epoch[10/10], Valid Loss: 0.0681: 100%|██████████| 157/157 [00:01<00:00, 106.00it/s]

    Epoch [10/10], Train Loss: 0.2111, Train Accuracy: 0.9221, Valid Loss: 0.2511, Valid Accuracy: 0.9109
    
    
    Best Validation Accuracy: 0.9109
    

    
    

- 시간이 비교적 많이 걸렸다.

### 3.4 결과 시각화(그냥 해봄)


```python
# 일부 샘플 예측
sample_loader = DataLoader(test_data, batch_size=10, shuffle=True)
samples, labels = next(iter(sample_loader))
samples, labels = samples.to(device), labels.to(device)
outputs = model1(samples)
_, predicted = torch.max(outputs, 1)
```


```python
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(samples[i].cpu().squeeze(), cmap='gray')
    plt.title(f'Label: {labels[i].item()}\nPredicted: {predicted[i].item()}')
    plt.axis('off')
plt.show()
```


    
![png](240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_files/240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_66_0.png)
    


### 3.5 결과 및 소감

- 어라? 정확도가 0.9189에서 0.9109으로 떨어졌다. Adaptive pooling을 두 개 추가했는데 정확도가 떨어지는 이유가 뭘까..?   
 => 꼭 뭐를 추가한다고 해서 정확도가 항상 올라가지는 않음을 알 수 있었다. 이것저것 바꿔가면서 성능을 올려볼까 했지만 시간상의 이유로 이쯤에서 넘어가야겠다. 시도했다는 것에 의의를 두고 정확도가 더 높은 첫 CNN 모델을 사용하는 걸로..



---



##4. Fashion MNIST 데이터셋을 Sampler를 통해 일부의 데이터만 레이블을 활용하도록 변경

- 4.1 훈련 데이터가 60,000개라면, 6,000개의 레이블 데이터, 54,000개의 레이블이 없는 데이터를 활용
- 4.2 하나의 배치는 모두 레이블이 없거나, 모두 레이블이 있어야 함
- 4.3 레이블이 있는 배치라면 -> 교차 엔트로피로 훈련   
  레이블이 없는 배치라면 -> pass

### 4.0 라이브러리 임포트 & 데이터 준비


```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset, ConcatDataset, random_split, SubsetRandomSampler
from torchvision import datasets, transforms
```


```python
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)
```


```python
# 6,000개의 레이블 데이터, 54,000개의 레이블이 없는 데이터를 활용
num_labeled = 6000
num_unlabeled = len(train_dataset) - num_labeled

indices = torch.randperm(len(train_dataset))
labeled_indices = indices[:num_labeled]
unlabeled_indices = indices[num_labeled:]

labeled_subset = Subset(train_dataset, labeled_indices)
unlabeled_subset = Subset(train_dataset, unlabeled_indices)
```

### 4.1 train_model, evalutate_model 함수 정의


```python
def train_model(model, labeled_loader, unlabeled_loader, criterion, optimizer, device, num_epochs=10):
    for epoch in range(num_epochs):
        model.train()
        # tqdm을 사용하여 labeled_loader와 unlabeled_loader의 진행률을 표시
        for (labeled_batch, unlabeled_batch) in tqdm(zip(labeled_loader, unlabeled_loader), total=min(len(labeled_loader), len(unlabeled_loader)), desc=f"Epoch {epoch+1}/{num_epochs}"):
            labeled_inputs, labeled_targets = labeled_batch
            labeled_inputs, labeled_targets = labeled_inputs.to(device), labeled_targets.to(device)

            # 레이블이 있는 배치 훈련
            optimizer.zero_grad()
            outputs = model(labeled_inputs)
            loss = criterion(outputs, labeled_targets)
            loss.backward()
            optimizer.step()

            # 레이블이 없는 배치는 pass

        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
```


```python
def evaluate_model(model, data_loader, criterion, device):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for inputs, targets in data_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            test_loss += criterion(outputs, targets).item() * inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == targets).sum().item()

    test_loss = test_loss / len(data_loader.dataset)
    accuracy = correct / len(data_loader.dataset)
    return test_loss, accuracy
```

### 4.2 CNN 모델

4.2.1 CNN 모델 정의


```python
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(64*7*7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, 2)
        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# 데이터로더 정의
batch_size = 64

labeled_sampler = SubsetRandomSampler(labeled_indices)
unlabeled_sampler = SubsetRandomSampler(unlabeled_indices)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

labeled_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=labeled_sampler)
unlabeled_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=unlabeled_sampler)
```

4.2.2 모델, 손실함수, 옵티마이저 정의


```python
model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
```




    SimpleCNN(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fc1): Linear(in_features=3136, out_features=128, bias=True)
      (fc2): Linear(in_features=128, out_features=10, bias=True)
    )



4.2.3 학습과 평가 진행


```python
num_epochs = 10

train_model(model, labeled_loader, unlabeled_loader, criterion, optimizer, device, num_epochs)
```

    Epoch 1/10: 100%|██████████| 94/94 [00:03<00:00, 30.96it/s]
    

    Epoch [1/10], Loss: 0.1481
    

    Epoch 2/10: 100%|██████████| 94/94 [00:03<00:00, 30.91it/s]
    

    Epoch [2/10], Loss: 0.2727
    

    Epoch 3/10: 100%|██████████| 94/94 [00:02<00:00, 32.58it/s]
    

    Epoch [3/10], Loss: 0.3224
    

    Epoch 4/10: 100%|██████████| 94/94 [00:03<00:00, 31.22it/s]
    

    Epoch [4/10], Loss: 0.0881
    

    Epoch 5/10: 100%|██████████| 94/94 [00:02<00:00, 31.59it/s]
    

    Epoch [5/10], Loss: 0.0963
    

    Epoch 6/10: 100%|██████████| 94/94 [00:02<00:00, 32.79it/s]
    

    Epoch [6/10], Loss: 0.1399
    

    Epoch 7/10: 100%|██████████| 94/94 [00:02<00:00, 31.78it/s]
    

    Epoch [7/10], Loss: 0.0911
    

    Epoch 8/10: 100%|██████████| 94/94 [00:02<00:00, 33.16it/s]
    

    Epoch [8/10], Loss: 0.0665
    

    Epoch 9/10: 100%|██████████| 94/94 [00:02<00:00, 31.65it/s]
    

    Epoch [9/10], Loss: 0.0667
    

    Epoch 10/10: 100%|██████████| 94/94 [00:03<00:00, 31.06it/s]

    Epoch [10/10], Loss: 0.0444
    

    
    


```python
test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, device)
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')
```

    Test Loss: 0.5095, Test Accuracy: 0.8726
    

### 4.3 결과 시각화(그냥 해봄)


```python
# 일부 샘플 예측
sample_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)
samples, labels = next(iter(sample_loader))
samples, labels = samples.to(device), labels.to(device)
outputs = model(samples)
_, predicted = torch.max(outputs, 1)
```


```python
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(samples[i].cpu().squeeze(), cmap='gray')
    plt.title(f'Label: {labels[i].item()}\nPredicted: {predicted[i].item()}')
    plt.axis('off')
plt.show()
```


    
![png](240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_files/240628_Pytorch%EA%B3%BC%EC%A0%9C_%EB%82%9C%EC%9D%B4%EB%8F%84%EC%A4%911_89_0.png)
    


##5. 3, 4의 훈련/검증 세트의 손실값 및 정확도 비교

| Scenario                                | Test Loss | Test Accuracy |
|-----------------------------------------|-----------|---------------|
| 모든 데이터를 레이블로 활용(3) | 0.2306    | 0.9189        |
| 일부 데이터만 레이블로 활용(4) | 0.5095    | 0.8726        |


=> 모든 데이터를 레이블로 활용한 경우에 Accuray값이 더 크게 나온다.   
(∵더 많은 레이블 데이터로 모델이 더 잘 학습할 수 있기 때문!)
