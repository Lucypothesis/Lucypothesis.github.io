# CVBê°•ì˜18-CAMì‹œê°í™”í•´ë³´ê¸°

**ëª©ì°¨**
1. ResNet-18ì˜ Grad-CAM ê²°ê³¼ í™•ì¸í•˜ê¸°   
  1.1 ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ResNet-18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°   
  1.2 ëª¨ë¸ì˜ Grad-CAM ê²°ê³¼ êµ¬í•˜ê¸°   
  1.3 Classì— ë”°ë¥¸ GradCAM ê²°ê³¼ ì‹œê°í™”í•´ë³´ê¸°   
  1.4 ì—¬ëŸ¬ Objectê°€ ìˆëŠ” ì´ë¯¸ì§€ì— ëŒ€í•œ GradCAM ê²°ê³¼ ì‹œê°í™” í•´ë³´ê¸°   
2. VGG-19ì˜ Grad-CAM ê²°ê³¼ í™•ì¸í•˜ê¸°   
  2.1 VGG-19 ëª¨ë¸ ë¡œë“œ ë° GradCAM ê³„ì‚°   
  2.2 Grad-CAM ê²°ê³¼ ì‹œê°í™”   

## 0. í™˜ê²½ì„¤ì •


```python
!pip install torch==2.0.1 -q
!pip install torchvision==0.15.2 -q
!pip install gdown==4.6.6 -q
!curl -OL https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt
```

    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m619.9/619.9 MB[0m [31m3.0 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m317.1/317.1 MB[0m [31m3.7 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m11.8/11.8 MB[0m [31m84.1 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21.0/21.0 MB[0m [31m73.2 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m849.3/849.3 kB[0m [31m42.7 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m557.1/557.1 MB[0m [31m3.3 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m168.4/168.4 MB[0m [31m7.7 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m54.6/54.6 MB[0m [31m12.8 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m102.6/102.6 MB[0m [31m8.1 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m173.2/173.2 MB[0m [31m5.3 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m177.1/177.1 MB[0m [31m5.9 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m98.6/98.6 kB[0m [31m6.0 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m63.3/63.3 MB[0m [31m11.2 MB/s[0m eta [36m0:00:00[0m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m96.4/96.4 kB[0m [31m6.5 MB/s[0m eta [36m0:00:00[0m
    [?25h[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.
    torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.
    torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.0.1 which is incompatible.[0m[31m
    [2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m6.0/6.0 MB[0m [31m41.2 MB/s[0m eta [36m0:00:00[0m
    [?25h  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
    100 10472  100 10472    0     0  63475      0 --:--:-- --:--:-- --:--:-- 63853
    


```python
import matplotlib.pyplot as plt
from PIL import Image
import PIL
import cv2
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision
import torchvision.transforms as T
```

## 1. ResNet-18ì˜ Grad-CAM ê²°ê³¼ í™•ì¸í•˜ê¸°

### 1.1 ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ResNet-18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°


```python
im = Image.open('/content/dog.jpg').resize((512,512))
plt.imshow(im)
```




    <matplotlib.image.AxesImage at 0x7beceb3905b0>




    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_7_1.png)
    



```python
# ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ëŠ” modelì˜ inputë¡œ ì“¸ ìˆ˜ ìˆë„ë¡ ì „ì²˜ë¦¬í•¨
preprocess = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256), # ì´ë¯¸ì§€ì˜ ì§§ì€ ë³€ì´ 256ì´ ë˜ë„ë¡ ì¡°
    torchvision.transforms.CenterCrop(224), # ì´ë¯¸ì§€ì˜ ì¤‘ì•™ ë¶€ë¶„ì„ 224x224 í¬ê¸°ë¡œ ìë¦„
    torchvision.transforms.ToTensor(), # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ì´ë¯¸ì§€ ì •ê·œí™”. RGB ê° ì±„ë„ì— ëŒ€í•œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
])
```


```python
# torch.hubì—ì„œ ì›í•˜ëŠ” ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê³  ê°€ì†í™˜ê²½ ì„¤ì •í•´ì£¼ê¸°
model = torch.hub.load('pytorch/vision', 'resnet18', weights = 'ResNet18_Weights.DEFAULT')
device = 'cpu'
model = model.to(device).eval()
im_tensor = preprocess(im).unsqueeze(0).to(device)
print(model)
```

    Downloading: "https://github.com/pytorch/vision/zipball/main" to /root/.cache/torch/hub/main.zip
    Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 131MB/s]
    

    ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=1000, bias=True)
    )
    

### 1.2 ëª¨ë¸ì˜ Grad-CAM ê²°ê³¼ êµ¬í•˜ê¸°

`register_forward_hook`ì€ forward()í•¨ìˆ˜ê°€ ê³„ì‚°ë  ë•Œë§ˆë‹¤ ë¶ˆë¦¬ê²Œ ë˜ê³ , `register_backward_hook`ì€ target layerê°€ gradientê°€ ì¡´ì¬í•˜ëŠ” ëª¨ë“ˆì¸ ê²½ìš° ìë™ìœ¼ë¡œ ë¶ˆë¦¬ê²Œ ë¨


```python
class GradCam(nn.Module):
  def __init__(self, model, module, layer):
    super().__init__()
    self.model = model
    self.module = module
    self.layer = layer
    self.register_hooks()

  # ëª¨ë¸ì˜ íŠ¹ì • ë ˆì´ì–´ì— forward ë° backward í›„í¬ë¥¼ ë“±ë¡í•˜ì—¬ Grad-CAM í™œì„±í™” ë§´ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ê¸°ì´ˆì‘ì—…ì„ ìˆ˜í–‰í•¨

  # register_forward_hook: Target Layerì— ëŒ€í•´ forward passë¥¼ í†µí•´ feature mapë¥¼ ì–»ìŒ
  # register_backward_hook: Target Layerì— ëŒ€í•´ backward passë¥¼ í†µí•´ gradientë¥¼ ê³„ì‚°
  def register_hooks(self):

    # _modules.items(): ëª¨ë¸ì˜ ëª¨ë“ˆ ì´ë¦„ê³¼ ëª¨ë“ˆ ìì²´ë¥¼ ë°˜í™˜
    for module_name, module in self.model._modules.items():
      if module_name == self.module:
        for layer_name, module in module._modules.items():
          if layer_name == self.layer:

            # í˜„ì¬ ëª¨ë“ˆì´ ì„œë¸Œëª¨ë“ˆì„ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸
            if len(module._modules.items()) != 0:

              # ë§¨ ë’¤ì— ìˆëŠ” ì„œë¸Œëª¨ë“ˆ(batchnorm layer)ì— í›…ì„ ê±º
              list(module._modules.items())[-1][1].register_forward_hook(self.forward_hook)
              list(module._modules.items())[-1][1].register_backward_hook(self.backward_hook)

              # ì–´ë–¤ target layerì— í›…ì´ ê±¸ë ¸ëŠ”ì§€ í™•ì¸
              print(f'Target Layer is {module_name}-{layer_name}, {list(module._modules.items())[-1][1]}')

            # ResNetì´ ì•„ë‹Œ ëª¨ë¸ì—ì„œë„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ elseë¬¸ ì²˜ë¦¬í•¨
            else:
              # í˜„ì¬ ëª¨ë“ˆì— ì§ì ‘ í›…ì„ ê±º
              module.register_forward_hook(self.forward_hook)
              module.register_backward_hook(self.backward_hook)
              print(f'Target Layer is {module_name}-{layer_name}')

  def forward(self, input, target_class):

    # ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì— í†µê³¼ì‹œì¼œ ì¶œë ¥ì„ ê³„ì‚°
    # outs.shape = [Batch, # of Class]
    outs = self.model(input)

    # ë°°ì¹˜ ì°¨ì›ì„ ì œê±°í•˜ì—¬ ì¶œë ¥ì„ ì••ì¶•í•¨. ë°°ì¹˜í¬ê¸°ê°€ 1ì¼ ê²½ìš° ë¶ˆí•„ìš”í•œ ì°¨ì›ì„ ì œê±°í•˜ê¸° ìœ„í•¨
    # outs.shape = [# of Class]
    outs = outs.squeeze()

    # targe class optionì„ ì£¼ì§€ ì•Šì„ ê²½ìš° ê°€ì¥ ë†’ì€ scoreë¥¼ ê°€ì§„ classì˜ activation mapì„ ì‹œê°í™” í•¨
    if target_class is None:
      target_class = outs.argmax()

    # target classì— ëŒ€í•´ì„œ backward passë¥¼ ì§„í–‰í•¨
    # retain_graph = True: ê·¸ë˜í”„ë¥¼ ìœ ì§€í•˜ì—¬ ì´í›„ ì¶”ê°€ì ì¸ backward ì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•¨
    outs[target_class].backward(retain_graph=True)

    # ê° Channelë§ˆë‹¤ Gradientë“¤ì˜ í‰ê· ì„ êµ¬í•¨
    # dim=(1,2): ê·¸ë¼ë””ì–¸íŠ¸ í…ì„œì˜ ë†’ì´ì™€ ë„ˆë¹„ì— ëŒ€í•´ í‰ê· ì„ ê³„ì‚°
    # keepdim=True: ê³„ì‚°ëœ í‰ê· ì„ ìœ ì§€í•˜ì—¬ í…ì„œì˜ ì°¨ì›ì„ ìœ ì§€
    a_k = torch.mean(self.backward_result, dim=(1,2), keepdim=True)

    # Forward pass ê²°ê³¼ì™€ Backward pass ê²°ê³¼ë¡œ êµ¬í•œ gradient(weight)ë¥¼ ê³±í•´ì¤Œ
    importance_weights = torch.sum(a_k * self.forward_result, dim=0)
    # ReLU í•¨ìˆ˜ë¥¼ í†µí•´ ìŒìˆ˜ë¥¼ ì œê±°í•´ì£¼ê³ , ìµœëŒ“ê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ [0,1]ì˜ ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ normalize í•´ì¤Œ
    # torch.max(importance_weights): ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ì˜ ìµœëŒ“ê°’. ì´ ê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì •ê·œí™”í•¨
    activation_map = torch.relu(importance_weights) / torch.max(importance_weights)

    # ìƒì„±ëœ í™œì„±í™”ë§µ, ëª¨ë¸ì˜ ì¶œë ¥ê²°ê³¼, ëª¨ë¸ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ ë°˜í™˜
    return activation_map, outs, outs.argmax()

  def forward_hook(self, _, input, output):
    self.forward_result = torch.squeeze(output)

  def backward_hook(self, _, grad_input, grad_output):
    self.backward_result = torch.squeeze(grad_output[0])
```


```python
# ë§¨ ë§ˆì§€ë§‰ ë ˆì´ì–´(layer4)ì˜ ë§¨ ë§ˆì§€ë§‰ ë¸”ëŸ­(layer='1')
grad_cam = GradCam(model=model, module='layer4', layer='1')
mask, outs, cls_pred = grad_cam(im_tensor, None)

# activation mapì˜ sizeë¥¼ í™•ì¸í•¨
print(mask.shape, cls_pred.item())

# activation mapì„ ì‹œê°í™”í•¨
# mask.cpu(): í…ì„œë¥¼ cpuë¡œ ì´ë™ / detach(): í…ì„œë¥¼ í˜„ì¬ ê³„ì‚° ê·¸ë˜í”„ì—ì„œ ë¶„ë¦¬ / squeeze(): ë¶ˆí•„ìš”í•œ ì°¨ì› ì œê±° / numpy(): í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜(matplotlib ì´ë¯¸ì§€ ì‹œê°í™”ë¥¼ ìœ„í•´)
plt.imshow(mask.cpu().detach().squeeze().numpy())
```

    Target Layer is layer4-1, BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    

    /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
      warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
    

    torch.Size([7, 7]) 153
    




    <matplotlib.image.AxesImage at 0x7bece791b100>




    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_13_4.png)
    


### 1.3 Classì— ë”°ë¥¸ GradCAM ê²°ê³¼ ì‹œê°í™”í•´ë³´ê¸°


```python
def overlay_mask(img, mask):
  # ì‹œê°í™”ë¥¼ ìœ„í•´ class activation mapì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜ì‹œì¼œì¤Œ
  img_size = img.size
  mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0), [img_size[1], img_size[0]], mode='bilinear')
  mask = mask.cpu().detach().squeeze().numpy()

  # ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— activation mapì„ ê·¸ë ¤ì¤Œ
  plt.imshow(img)
  plt.imshow(mask, cmap='jet', alpha=0.5)
```


```python
with open('../content/imagenet_classes.txt', 'r') as f:
  classes = [s.strip() for s in f.readlines()]

# softmax ê²°ê³¼ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” 3ê°œì˜ classë¥¼ ì¶œë ¥
probabilities = torch.nn.functional.softmax(outs, dim=0)
top3_prob, top3_classes = torch.topk(probabilities, 3)

fig = plt.figure(figsize=(20,20))
for i in range(top3_prob.size(0)):
  mask, _, _ = grad_cam(im_tensor, int(top3_classes[i].item()))

  a = fig.add_subplot(1,3,i+1)
  overlay_mask(im, mask)
  a.set_title(f'Class: {classes[top3_classes[i]]}, Score {top3_prob[i].item(): .4f}', fontsize=10)
```


    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_16_0.png)
    



```python
# softmax ê²°ê³¼ ê°€ì¥ ë‚®ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” 3ê°œì˜ class ì¶œë ¥
low_prob, low_classes = torch.topk(probabilities, 1000)

fig = plt.figure(figsize=(20,20))
for i in range(1,4):
  mask, _, _ = grad_cam(im_tensor, int(low_classes[-i].item()))

  a = fig.add_subplot(1,3,i)
  overlay_mask(im, mask)
  a.set_title(f'Class: {classes[low_classes[i]]}, Score {low_prob[i].item(): .4f}', fontsize=10)
```


    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_17_0.png)
    


### 1.4 ì—¬ëŸ¬ Objectê°€ ìˆëŠ” ì´ë¯¸ì§€ì— ëŒ€í•œ GradCAM ê²°ê³¼ ì‹œê°í™” í•´ë³´ê¸°


```python
# ì—¬ëŸ¬ objectê°€ ìˆëŠ” ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ í•´ë³´ê¸°
im2 = Image.open('/content/dog_cat.png').convert('RGB')
plt.imshow(im2)

im_tensor2 = preprocess(im2)
im_tensor2 = im_tensor2.unsqueeze(0).to(device) # ì´ë¯¸ì§€ë¥¼ batch í˜•íƒœë¡œ ë°”ê¿”ì¤Œ(BxCxWxH)
```


    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_19_0.png)
    



```python
# ë§ˆì§€ë§‰ Batch Normalization Layerì— ëŒ€í•œ Grad-CAMì„ êµ¬í•¨
grad_cam = GradCam(model=model, module='layer4', layer='1')

# 207, golden_retriever class(class num=207)
mask_dog, outs, cls_pred = grad_cam(im_tensor2, 207)
# 282, tiger_cat class(class num=282)
mask_cat, outs, cls_pred = grad_cam(im_tensor2, 282)
# 319, dragonfly class(class num=319)
mask_dragonfly, outs, cls_pred = grad_cam(im_tensor2, 319)

masks = [(207, mask_dog),(282, mask_cat),(319, mask_dragonfly)]

fig = plt.figure(figsize=(20,20))
for i in range(len(masks)):
  a = fig.add_subplot(1,3, i+1)
  overlay_mask(im2, masks[i][1])
  a.set_title(f'Class: {classes[masks[i][0]]}', fontsize=10)
```

    Target Layer is layer4-1, BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    


    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_20_1.png)
    


## 2. VGG-19ì˜ Grad-CAM ê²°ê³¼ í™•ì¸í•˜ê¸°

### 2.1 VGG-19 ëª¨ë¸ ë¡œë“œ ë° GradCAM ê³„ì‚°


```python
# ë‹¤ë¥¸ ëª¨ë¸ì— ëŒ€í•´ì„œë„ ì ìš©í•´ë³´ê¸°
model = torch.hub.load('pytorch/vision', 'vgg19', weights = 'VGG19_Weights.DEFAULT')

device = 'cpu'
model = model.to(device).eval()
print(model)
```

    Using cache found in /root/.cache/torch/hub/pytorch_vision_main
    Downloading: "https://download.pytorch.org/models/vgg19-dcbb9e9d.pth" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548M/548M [00:08<00:00, 71.4MB/s]
    

    VGG(
      (features): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace=True)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace=True)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace=True)
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (17): ReLU(inplace=True)
        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace=True)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace=True)
        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (24): ReLU(inplace=True)
        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (26): ReLU(inplace=True)
        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace=True)
        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (31): ReLU(inplace=True)
        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (33): ReLU(inplace=True)
        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (35): ReLU(inplace=True)
        (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
      (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=4096, bias=True)
        (4): ReLU(inplace=True)
        (5): Dropout(p=0.5, inplace=False)
        (6): Linear(in_features=4096, out_features=1000, bias=True)
      )
    )
    


```python
# VGG19ì˜ ë§ˆì§€ë§‰ ReLU Layerì— ëŒ€í•œ Grad-CAM ê²°ê³¼ë¥¼ ì–»ê¸°
grad_cam = GradCam(model=model, module='features', layer='35')
mask, outs, cls_pred = grad_cam(im_tensor, None)
print(mask.shape, cls_pred.item())
plt.imshow(mask.detach().cpu().numpy())
```

    Target Layer is features-35
    torch.Size([14, 14]) 203
    




    <matplotlib.image.AxesImage at 0x7bece635d180>




    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_24_2.png)
    


### 2.2 Grad-CAM ê²°ê³¼ ì‹œê°í™”


```python
# softmax ê²°ê³¼ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” 3ê°œì˜ class ì¶œë ¥
probabilities = torch.nn.functional.softmax(outs, dim=0)
top3_prob, top3_classes = torch.topk(probabilities, 3)

fig = plt.figure(figsize=(20,20))
for i in range(top3_prob.size(0)):
  mask, _, _ = grad_cam(im_tensor, int(top3_classes[i].item()))

  a = fig.add_subplot(1, 3, i+1)
  overlay_mask(im, mask)
  a.set_title(f'Class: {classes[top3_classes[i]]}, Score {top3_prob[i].item(): .4f}', fontsize=10)
```


    
![png](240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_files/240725_CVB%EA%B0%95%EC%9D%9818_CAM%EC%8B%9C%EA%B0%81%ED%99%94%ED%95%B4%EB%B3%B4%EA%B8%B0_26_0.png)
    

